{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e97cc5b-ed38-4fe6-8a8b-77328635982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "#import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna#载入optuna优化包\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695c49d0-083e-4d2e-aff9-ddf7deef9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##optuna######\n",
    "###耗费时间的过程。。。。。。。。。。。。。。。\n",
    "# Define a basic convolutional layer\n",
    "# 定义带参数的 GELU 激活函数层\n",
    "class GELUB(nn.Module): \n",
    "    def __init__(self, seqFlag, trial):\n",
    "        super().__init__()\n",
    "        self.sigma = trial.suggest_float(f'sigma_{seqFlag}', 0.0, 10.0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input * (1 + torch.erf(input / math.sqrt(2) / self.sigma)) / 2\n",
    "        return x\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "# 定义ResNet模型\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, trial, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = conv3x3(3, 16)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.custom1 = GELUB(1, trial)  # 自定义激活函数层\n",
    "\n",
    "        # Layer 1\n",
    "        self.layer1_conv1 = conv3x3(16, 16)\n",
    "        self.layer1_bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1_conv2 = conv3x3(16, 16)\n",
    "        self.layer1_bn2 = nn.BatchNorm2d(16)\n",
    "        self.layer1_extra_conv1 = conv3x3(16, 16)\n",
    "        self.layer1_extra_bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1_extra_conv2 = conv3x3(16, 16)\n",
    "        self.layer1_extra_bn2 = nn.BatchNorm2d(16)\n",
    "        self.gelub11 = GELUB(2, trial)\n",
    "        self.gelub12 = GELUB(3, trial)\n",
    "        self.gelub13 = GELUB(4, trial)\n",
    "        self.gelub14 = GELUB(5, trial)\n",
    "\n",
    "        # Layer 2\n",
    "        self.layer2_conv1 = conv3x3(16, 32, stride=2)\n",
    "        self.layer2_bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer2_conv2 = conv3x3(32, 32)\n",
    "        self.layer2_bn2 = nn.BatchNorm2d(32)\n",
    "        self.layer2_extra_conv1 = conv3x3(16, 32, stride=2)  # 调整residual的通道数\n",
    "        self.layer2_extra_bn1 = nn.BatchNorm2d(32)\n",
    "        self.layer2_extra_conv2 = conv3x3(32, 32)\n",
    "        self.layer2_extra_bn2 = nn.BatchNorm2d(32)\n",
    "        self.gelub21 = GELUB(6, trial)\n",
    "        self.gelub22 = GELUB(7, trial)\n",
    "        self.gelub23 = GELUB(8, trial)\n",
    "        self.gelub24 = GELUB(9, trial)\n",
    "        self.layer2_downsample = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        # Layer 3\n",
    "        self.layer3_conv1 = conv3x3(32, 64, stride=2)\n",
    "        self.layer3_bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer3_conv2 = conv3x3(64, 64)\n",
    "        self.layer3_bn2 = nn.BatchNorm2d(64)\n",
    "        self.layer3_extra_conv1 = conv3x3(32, 64, stride=2)  # 调整residual的通道数\n",
    "        self.layer3_extra_bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer3_extra_conv2 = conv3x3(64, 64)\n",
    "        self.layer3_extra_bn2 = nn.BatchNorm2d(64)\n",
    "        self.gelub31 = GELUB(10, trial)\n",
    "        self.gelub32 = GELUB(11, trial)\n",
    "        self.gelub33 = GELUB(12, trial)\n",
    "        self.gelub34 = GELUB(13, trial)\n",
    "\n",
    "        self.layer3_downsample = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 0\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.custom1(out)\n",
    "\n",
    "        # Layer 1\n",
    "        residual = out\n",
    "        out = self.layer1_conv1(out)\n",
    "        out = self.layer1_bn1(out)\n",
    "        out = self.gelub11(out)\n",
    "        out = self.layer1_conv2(out)\n",
    "        out = self.layer1_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub12(out)\n",
    "        \n",
    "        residual = out\n",
    "        out = self.layer1_extra_conv1(out)\n",
    "        out = self.layer1_extra_bn1(out)\n",
    "        out = self.gelub13(out)\n",
    "        out = self.layer1_extra_conv2(out)\n",
    "        out = self.layer1_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub14(out)\n",
    "\n",
    "        # Layer 2\n",
    "        residual = out\n",
    "        out = self.layer2_conv1(out)\n",
    "        out = self.layer2_bn1(out)\n",
    "        out = self.gelub21(out)\n",
    "        out = self.layer2_conv2(out)\n",
    "        out = self.layer2_bn2(out)\n",
    "        out = self.gelub22(out)\n",
    "        residual = self.layer2_downsample(residual)\n",
    "        out += residual\n",
    "        out = self.gelub22(out)\n",
    "\n",
    "        residual = out\n",
    "        out = self.layer2_extra_conv2(out)\n",
    "        out = self.layer2_extra_bn2(out)\n",
    "        out = self.gelub23(out)\n",
    "        out = self.layer2_extra_conv2(out)\n",
    "        out = self.layer2_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub24(out)\n",
    "\n",
    "        # Layer 3\n",
    "        residual = out\n",
    "        out = self.layer3_conv1(out)\n",
    "        out = self.layer3_bn1(out)\n",
    "        out = self.gelub31(out)\n",
    "        out = self.layer3_conv2(out)\n",
    "        out = self.layer3_bn2(out)\n",
    "        residual = self.layer3_downsample(residual)\n",
    "        out += residual\n",
    "        out = self.gelub32(out)\n",
    "        \n",
    "        residual = out\n",
    "        out = self.layer3_extra_conv2(out)\n",
    "        out = self.layer3_extra_bn2(out)\n",
    "        out = self.gelub33(out)\n",
    "        out = self.layer3_extra_conv2(out)\n",
    "        out = self.layer3_extra_bn2(out)\n",
    "        out += residual\n",
    "        out = self.gelub34(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9138592f-df35-4753-924a-f235d3b2e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 16:01:46,323] A new study created in memory with name: no-name-8f32d8d0-c0d9-4e58-8549-7cf7d904e27c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/80 \t Train Loss:1.4908 Valid Loss:1.2611 \t Train Acc:45.18 %  Valid Acc:54.42 %\n",
      "Epoch:2/80 \t Train Loss:1.1271 Valid Loss:1.0191 \t Train Acc:59.35 %  Valid Acc:63.37 %\n",
      "Epoch:3/80 \t Train Loss:0.9919 Valid Loss:0.9680 \t Train Acc:64.68 %  Valid Acc:65.38 %\n",
      "Epoch:4/80 \t Train Loss:0.8899 Valid Loss:0.8582 \t Train Acc:68.35 %  Valid Acc:69.74 %\n",
      "Epoch:5/80 \t Train Loss:0.8134 Valid Loss:0.7824 \t Train Acc:71.34 %  Valid Acc:73.45 %\n",
      "Epoch:6/80 \t Train Loss:0.7480 Valid Loss:0.6942 \t Train Acc:73.80 %  Valid Acc:75.98 %\n",
      "Epoch:7/80 \t Train Loss:0.6894 Valid Loss:0.6576 \t Train Acc:75.96 %  Valid Acc:77.29 %\n",
      "Epoch:8/80 \t Train Loss:0.6486 Valid Loss:0.6673 \t Train Acc:77.44 %  Valid Acc:77.50 %\n",
      "Epoch:9/80 \t Train Loss:0.6147 Valid Loss:0.6558 \t Train Acc:78.47 %  Valid Acc:77.78 %\n",
      "Epoch:10/80 \t Train Loss:0.5753 Valid Loss:0.5937 \t Train Acc:80.00 %  Valid Acc:79.70 %\n",
      "Epoch:11/80 \t Train Loss:0.5457 Valid Loss:0.6292 \t Train Acc:81.05 %  Valid Acc:78.80 %\n",
      "Epoch:12/80 \t Train Loss:0.5270 Valid Loss:0.5639 \t Train Acc:81.55 %  Valid Acc:81.00 %\n",
      "Epoch:13/80 \t Train Loss:0.5083 Valid Loss:0.5701 \t Train Acc:82.26 %  Valid Acc:80.33 %\n",
      "Epoch:14/80 \t Train Loss:0.4943 Valid Loss:0.5726 \t Train Acc:82.91 %  Valid Acc:80.61 %\n",
      "Epoch:15/80 \t Train Loss:0.4775 Valid Loss:0.5517 \t Train Acc:83.42 %  Valid Acc:81.70 %\n",
      "Epoch:16/80 \t Train Loss:0.4597 Valid Loss:0.5402 \t Train Acc:84.10 %  Valid Acc:82.40 %\n",
      "Epoch:17/80 \t Train Loss:0.4477 Valid Loss:0.5605 \t Train Acc:84.45 %  Valid Acc:81.18 %\n",
      "Epoch:18/80 \t Train Loss:0.4380 Valid Loss:0.5147 \t Train Acc:84.76 %  Valid Acc:82.83 %\n",
      "Epoch:19/80 \t Train Loss:0.4226 Valid Loss:0.4979 \t Train Acc:85.35 %  Valid Acc:83.64 %\n",
      "Epoch:20/80 \t Train Loss:0.4156 Valid Loss:0.4853 \t Train Acc:85.56 %  Valid Acc:83.66 %\n",
      "Epoch:21/80 \t Train Loss:0.3326 Valid Loss:0.4460 \t Train Acc:88.40 %  Valid Acc:85.56 %\n",
      "Epoch:22/80 \t Train Loss:0.3149 Valid Loss:0.4525 \t Train Acc:89.02 %  Valid Acc:85.60 %\n",
      "Epoch:23/80 \t Train Loss:0.3053 Valid Loss:0.4279 \t Train Acc:89.28 %  Valid Acc:86.24 %\n",
      "Epoch:24/80 \t Train Loss:0.3006 Valid Loss:0.4348 \t Train Acc:89.50 %  Valid Acc:85.97 %\n",
      "Epoch:25/80 \t Train Loss:0.2969 Valid Loss:0.4286 \t Train Acc:89.73 %  Valid Acc:86.29 %\n",
      "Epoch:26/80 \t Train Loss:0.2926 Valid Loss:0.4260 \t Train Acc:89.76 %  Valid Acc:86.22 %\n",
      "Epoch:27/80 \t Train Loss:0.2827 Valid Loss:0.4337 \t Train Acc:90.13 %  Valid Acc:86.17 %\n",
      "Epoch:28/80 \t Train Loss:0.2794 Valid Loss:0.4302 \t Train Acc:90.21 %  Valid Acc:86.19 %\n",
      "Epoch:29/80 \t Train Loss:0.2746 Valid Loss:0.4245 \t Train Acc:90.39 %  Valid Acc:86.15 %\n",
      "Epoch:30/80 \t Train Loss:0.2710 Valid Loss:0.4389 \t Train Acc:90.42 %  Valid Acc:86.18 %\n",
      "Epoch:31/80 \t Train Loss:0.2669 Valid Loss:0.4320 \t Train Acc:90.59 %  Valid Acc:86.07 %\n",
      "Epoch:32/80 \t Train Loss:0.2659 Valid Loss:0.4343 \t Train Acc:90.73 %  Valid Acc:86.15 %\n",
      "Epoch:33/80 \t Train Loss:0.2589 Valid Loss:0.4372 \t Train Acc:90.88 %  Valid Acc:86.25 %\n",
      "Epoch:34/80 \t Train Loss:0.2545 Valid Loss:0.4321 \t Train Acc:91.01 %  Valid Acc:86.61 %\n",
      "Epoch:35/80 \t Train Loss:0.2565 Valid Loss:0.4418 \t Train Acc:91.07 %  Valid Acc:86.01 %\n",
      "Epoch:36/80 \t Train Loss:0.2472 Valid Loss:0.4352 \t Train Acc:91.30 %  Valid Acc:86.50 %\n",
      "Epoch:37/80 \t Train Loss:0.2438 Valid Loss:0.4305 \t Train Acc:91.33 %  Valid Acc:86.89 %\n",
      "Epoch:38/80 \t Train Loss:0.2442 Valid Loss:0.4475 \t Train Acc:91.38 %  Valid Acc:86.21 %\n",
      "Epoch:39/80 \t Train Loss:0.2377 Valid Loss:0.4293 \t Train Acc:91.50 %  Valid Acc:86.72 %\n",
      "Epoch:40/80 \t Train Loss:0.2386 Valid Loss:0.4561 \t Train Acc:91.55 %  Valid Acc:86.17 %\n",
      "Epoch:41/80 \t Train Loss:0.2065 Valid Loss:0.4346 \t Train Acc:92.77 %  Valid Acc:86.88 %\n",
      "Epoch:42/80 \t Train Loss:0.1983 Valid Loss:0.4339 \t Train Acc:93.02 %  Valid Acc:86.95 %\n",
      "Epoch:43/80 \t Train Loss:0.1984 Valid Loss:0.4264 \t Train Acc:93.01 %  Valid Acc:86.94 %\n",
      "Epoch:44/80 \t Train Loss:0.1933 Valid Loss:0.4358 \t Train Acc:93.12 %  Valid Acc:87.10 %\n",
      "Epoch:45/80 \t Train Loss:0.1951 Valid Loss:0.4415 \t Train Acc:93.15 %  Valid Acc:86.98 %\n",
      "Epoch:46/80 \t Train Loss:0.1915 Valid Loss:0.4493 \t Train Acc:93.22 %  Valid Acc:86.96 %\n",
      "Epoch:47/80 \t Train Loss:0.1910 Valid Loss:0.4327 \t Train Acc:93.34 %  Valid Acc:87.42 %\n",
      "Epoch:48/80 \t Train Loss:0.1897 Valid Loss:0.4389 \t Train Acc:93.42 %  Valid Acc:87.22 %\n",
      "Epoch:49/80 \t Train Loss:0.1878 Valid Loss:0.4363 \t Train Acc:93.28 %  Valid Acc:87.18 %\n",
      "Epoch:50/80 \t Train Loss:0.1860 Valid Loss:0.4602 \t Train Acc:93.35 %  Valid Acc:86.61 %\n",
      "Epoch:51/80 \t Train Loss:0.1854 Valid Loss:0.4408 \t Train Acc:93.50 %  Valid Acc:87.16 %\n",
      "Epoch:52/80 \t Train Loss:0.1833 Valid Loss:0.4532 \t Train Acc:93.52 %  Valid Acc:87.15 %\n",
      "Epoch:53/80 \t Train Loss:0.1817 Valid Loss:0.4475 \t Train Acc:93.53 %  Valid Acc:87.07 %\n",
      "Epoch:54/80 \t Train Loss:0.1809 Valid Loss:0.4509 \t Train Acc:93.45 %  Valid Acc:87.37 %\n",
      "Epoch:55/80 \t Train Loss:0.1788 Valid Loss:0.4545 \t Train Acc:93.76 %  Valid Acc:87.19 %\n",
      "Epoch:56/80 \t Train Loss:0.1794 Valid Loss:0.4422 \t Train Acc:93.68 %  Valid Acc:87.34 %\n",
      "Epoch:57/80 \t Train Loss:0.1773 Valid Loss:0.4440 \t Train Acc:93.80 %  Valid Acc:87.24 %\n",
      "Epoch:58/80 \t Train Loss:0.1750 Valid Loss:0.4566 \t Train Acc:93.72 %  Valid Acc:87.34 %\n",
      "Epoch:59/80 \t Train Loss:0.1791 Valid Loss:0.4550 \t Train Acc:93.77 %  Valid Acc:87.03 %\n",
      "Epoch:60/80 \t Train Loss:0.1743 Valid Loss:0.4497 \t Train Acc:93.78 %  Valid Acc:87.51 %\n",
      "Epoch:61/80 \t Train Loss:0.1638 Valid Loss:0.4488 \t Train Acc:94.30 %  Valid Acc:87.43 %\n",
      "Epoch:62/80 \t Train Loss:0.1619 Valid Loss:0.4576 \t Train Acc:94.23 %  Valid Acc:87.32 %\n",
      "Epoch:63/80 \t Train Loss:0.1604 Valid Loss:0.4585 \t Train Acc:94.34 %  Valid Acc:87.41 %\n",
      "Epoch:64/80 \t Train Loss:0.1571 Valid Loss:0.4529 \t Train Acc:94.30 %  Valid Acc:87.34 %\n",
      "Epoch:65/80 \t Train Loss:0.1564 Valid Loss:0.4552 \t Train Acc:94.45 %  Valid Acc:87.22 %\n",
      "Epoch:66/80 \t Train Loss:0.1584 Valid Loss:0.4558 \t Train Acc:94.38 %  Valid Acc:87.38 %\n",
      "Epoch:67/80 \t Train Loss:0.1575 Valid Loss:0.4600 \t Train Acc:94.41 %  Valid Acc:87.35 %\n",
      "Epoch:68/80 \t Train Loss:0.1548 Valid Loss:0.4615 \t Train Acc:94.43 %  Valid Acc:87.43 %\n",
      "Epoch:69/80 \t Train Loss:0.1570 Valid Loss:0.4622 \t Train Acc:94.46 %  Valid Acc:87.26 %\n",
      "Epoch:70/80 \t Train Loss:0.1519 Valid Loss:0.4645 \t Train Acc:94.57 %  Valid Acc:87.31 %\n",
      "Epoch:71/80 \t Train Loss:0.1554 Valid Loss:0.4585 \t Train Acc:94.52 %  Valid Acc:87.61 %\n",
      "Epoch:72/80 \t Train Loss:0.1551 Valid Loss:0.4627 \t Train Acc:94.51 %  Valid Acc:87.39 %\n",
      "Epoch:73/80 \t Train Loss:0.1564 Valid Loss:0.4622 \t Train Acc:94.44 %  Valid Acc:87.36 %\n",
      "Epoch:74/80 \t Train Loss:0.1555 Valid Loss:0.4666 \t Train Acc:94.53 %  Valid Acc:87.48 %\n",
      "Epoch:75/80 \t Train Loss:0.1550 Valid Loss:0.4650 \t Train Acc:94.49 %  Valid Acc:87.27 %\n",
      "Epoch:76/80 \t Train Loss:0.1531 Valid Loss:0.4656 \t Train Acc:94.53 %  Valid Acc:87.34 %\n",
      "Epoch:77/80 \t Train Loss:0.1495 Valid Loss:0.4618 \t Train Acc:94.71 %  Valid Acc:87.55 %\n",
      "Epoch:78/80 \t Train Loss:0.1515 Valid Loss:0.4724 \t Train Acc:94.60 %  Valid Acc:87.38 %\n",
      "Epoch:79/80 \t Train Loss:0.1524 Valid Loss:0.4647 \t Train Acc:94.51 %  Valid Acc:87.43 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 16:52:08,556] Trial 0 finished with value: 87.37 and parameters: {'sigma_1': 4.446965845522028, 'sigma_2': 2.5738228033584543, 'sigma_3': 5.484707396012755, 'sigma_4': 7.447966654690194, 'sigma_5': 8.198999970169526, 'sigma_6': 0.24587717173912949, 'sigma_7': 8.339356211290225, 'sigma_8': 5.184410352497476, 'sigma_9': 1.3588377440310206, 'sigma_10': 3.2682422692579918, 'sigma_11': 5.9506674592661115, 'sigma_12': 1.0630871083712756, 'sigma_13': 6.803571010214274}. Best is trial 0 with value: 87.37.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:80/80 \t Train Loss:0.1501 Valid Loss:0.4671 \t Train Acc:94.70 %  Valid Acc:87.37 %\n",
      "Epoch:1/80 \t Train Loss:1.5713 Valid Loss:1.5430 \t Train Acc:41.68 %  Valid Acc:45.56 %\n",
      "Epoch:2/80 \t Train Loss:1.2719 Valid Loss:1.1742 \t Train Acc:54.08 %  Valid Acc:57.78 %\n",
      "Epoch:3/80 \t Train Loss:1.1121 Valid Loss:1.0449 \t Train Acc:59.96 %  Valid Acc:62.89 %\n",
      "Epoch:4/80 \t Train Loss:1.0118 Valid Loss:0.9191 \t Train Acc:64.12 %  Valid Acc:67.13 %\n",
      "Epoch:5/80 \t Train Loss:0.9109 Valid Loss:0.8583 \t Train Acc:67.83 %  Valid Acc:69.46 %\n",
      "Epoch:6/80 \t Train Loss:0.8365 Valid Loss:0.7877 \t Train Acc:70.43 %  Valid Acc:72.52 %\n",
      "Epoch:7/80 \t Train Loss:0.7682 Valid Loss:0.7670 \t Train Acc:73.17 %  Valid Acc:73.55 %\n",
      "Epoch:8/80 \t Train Loss:0.7238 Valid Loss:0.7812 \t Train Acc:74.60 %  Valid Acc:73.13 %\n",
      "Epoch:9/80 \t Train Loss:0.6763 Valid Loss:0.7040 \t Train Acc:76.48 %  Valid Acc:75.62 %\n",
      "Epoch:10/80 \t Train Loss:0.6392 Valid Loss:0.6622 \t Train Acc:77.76 %  Valid Acc:77.16 %\n",
      "Epoch:11/80 \t Train Loss:0.6023 Valid Loss:0.6268 \t Train Acc:78.90 %  Valid Acc:78.91 %\n",
      "Epoch:12/80 \t Train Loss:0.5810 Valid Loss:0.6230 \t Train Acc:79.86 %  Valid Acc:79.10 %\n",
      "Epoch:13/80 \t Train Loss:0.5599 Valid Loss:0.6216 \t Train Acc:80.55 %  Valid Acc:78.98 %\n",
      "Epoch:14/80 \t Train Loss:0.5396 Valid Loss:0.5914 \t Train Acc:81.48 %  Valid Acc:80.06 %\n",
      "Epoch:15/80 \t Train Loss:0.5227 Valid Loss:0.6252 \t Train Acc:82.01 %  Valid Acc:78.60 %\n",
      "Epoch:16/80 \t Train Loss:0.5055 Valid Loss:0.5586 \t Train Acc:82.56 %  Valid Acc:81.01 %\n",
      "Epoch:17/80 \t Train Loss:0.4874 Valid Loss:0.5207 \t Train Acc:83.20 %  Valid Acc:82.24 %\n",
      "Epoch:18/80 \t Train Loss:0.4745 Valid Loss:0.5417 \t Train Acc:83.61 %  Valid Acc:82.19 %\n",
      "Epoch:19/80 \t Train Loss:0.4698 Valid Loss:0.5956 \t Train Acc:83.82 %  Valid Acc:81.05 %\n",
      "Epoch:20/80 \t Train Loss:0.4525 Valid Loss:0.5174 \t Train Acc:84.31 %  Valid Acc:83.04 %\n",
      "Epoch:21/80 \t Train Loss:0.3658 Valid Loss:0.4706 \t Train Acc:87.32 %  Valid Acc:84.78 %\n",
      "Epoch:22/80 \t Train Loss:0.3501 Valid Loss:0.4657 \t Train Acc:87.85 %  Valid Acc:84.99 %\n",
      "Epoch:23/80 \t Train Loss:0.3397 Valid Loss:0.4647 \t Train Acc:88.14 %  Valid Acc:84.97 %\n",
      "Epoch:24/80 \t Train Loss:0.3323 Valid Loss:0.4675 \t Train Acc:88.40 %  Valid Acc:84.98 %\n",
      "Epoch:25/80 \t Train Loss:0.3259 Valid Loss:0.4763 \t Train Acc:88.67 %  Valid Acc:84.93 %\n",
      "Epoch:26/80 \t Train Loss:0.3221 Valid Loss:0.4590 \t Train Acc:88.70 %  Valid Acc:85.05 %\n",
      "Epoch:27/80 \t Train Loss:0.3137 Valid Loss:0.4632 \t Train Acc:89.01 %  Valid Acc:85.10 %\n",
      "Epoch:28/80 \t Train Loss:0.3119 Valid Loss:0.4781 \t Train Acc:89.11 %  Valid Acc:84.97 %\n",
      "Epoch:29/80 \t Train Loss:0.3104 Valid Loss:0.4695 \t Train Acc:89.20 %  Valid Acc:85.13 %\n",
      "Epoch:30/80 \t Train Loss:0.3025 Valid Loss:0.5066 \t Train Acc:89.53 %  Valid Acc:83.98 %\n",
      "Epoch:31/80 \t Train Loss:0.2992 Valid Loss:0.4527 \t Train Acc:89.47 %  Valid Acc:85.62 %\n",
      "Epoch:32/80 \t Train Loss:0.2905 Valid Loss:0.4748 \t Train Acc:89.81 %  Valid Acc:85.34 %\n",
      "Epoch:33/80 \t Train Loss:0.2885 Valid Loss:0.4692 \t Train Acc:89.93 %  Valid Acc:85.25 %\n",
      "Epoch:34/80 \t Train Loss:0.2843 Valid Loss:0.4729 \t Train Acc:90.03 %  Valid Acc:85.24 %\n",
      "Epoch:35/80 \t Train Loss:0.2801 Valid Loss:0.4691 \t Train Acc:90.15 %  Valid Acc:85.59 %\n",
      "Epoch:36/80 \t Train Loss:0.2767 Valid Loss:0.4639 \t Train Acc:90.25 %  Valid Acc:85.79 %\n",
      "Epoch:37/80 \t Train Loss:0.2718 Valid Loss:0.4643 \t Train Acc:90.40 %  Valid Acc:85.67 %\n",
      "Epoch:38/80 \t Train Loss:0.2752 Valid Loss:0.4693 \t Train Acc:90.33 %  Valid Acc:85.48 %\n",
      "Epoch:39/80 \t Train Loss:0.2693 Valid Loss:0.4696 \t Train Acc:90.48 %  Valid Acc:85.48 %\n",
      "Epoch:40/80 \t Train Loss:0.2666 Valid Loss:0.4728 \t Train Acc:90.53 %  Valid Acc:86.06 %\n",
      "Epoch:41/80 \t Train Loss:0.2313 Valid Loss:0.4469 \t Train Acc:91.79 %  Valid Acc:86.50 %\n",
      "Epoch:42/80 \t Train Loss:0.2254 Valid Loss:0.4465 \t Train Acc:92.03 %  Valid Acc:86.42 %\n",
      "Epoch:43/80 \t Train Loss:0.2213 Valid Loss:0.4473 \t Train Acc:92.17 %  Valid Acc:86.85 %\n",
      "Epoch:44/80 \t Train Loss:0.2198 Valid Loss:0.4514 \t Train Acc:92.31 %  Valid Acc:86.67 %\n",
      "Epoch:45/80 \t Train Loss:0.2193 Valid Loss:0.4556 \t Train Acc:92.39 %  Valid Acc:86.63 %\n",
      "Epoch:46/80 \t Train Loss:0.2122 Valid Loss:0.4545 \t Train Acc:92.55 %  Valid Acc:86.62 %\n",
      "Epoch:47/80 \t Train Loss:0.2157 Valid Loss:0.4559 \t Train Acc:92.45 %  Valid Acc:86.54 %\n",
      "Epoch:48/80 \t Train Loss:0.2121 Valid Loss:0.4596 \t Train Acc:92.64 %  Valid Acc:86.25 %\n",
      "Epoch:49/80 \t Train Loss:0.2128 Valid Loss:0.4516 \t Train Acc:92.43 %  Valid Acc:86.39 %\n",
      "Epoch:50/80 \t Train Loss:0.2097 Valid Loss:0.4650 \t Train Acc:92.56 %  Valid Acc:86.58 %\n",
      "Epoch:51/80 \t Train Loss:0.2085 Valid Loss:0.4579 \t Train Acc:92.65 %  Valid Acc:86.67 %\n",
      "Epoch:52/80 \t Train Loss:0.2098 Valid Loss:0.4639 \t Train Acc:92.66 %  Valid Acc:86.37 %\n",
      "Epoch:53/80 \t Train Loss:0.2100 Valid Loss:0.4643 \t Train Acc:92.47 %  Valid Acc:86.73 %\n",
      "Epoch:54/80 \t Train Loss:0.2005 Valid Loss:0.4694 \t Train Acc:92.91 %  Valid Acc:86.48 %\n",
      "Epoch:55/80 \t Train Loss:0.2007 Valid Loss:0.4687 \t Train Acc:92.75 %  Valid Acc:86.57 %\n",
      "Epoch:56/80 \t Train Loss:0.1976 Valid Loss:0.4759 \t Train Acc:93.02 %  Valid Acc:86.63 %\n",
      "Epoch:57/80 \t Train Loss:0.1989 Valid Loss:0.4690 \t Train Acc:93.00 %  Valid Acc:86.54 %\n",
      "Epoch:58/80 \t Train Loss:0.1981 Valid Loss:0.4639 \t Train Acc:92.98 %  Valid Acc:86.51 %\n",
      "Epoch:59/80 \t Train Loss:0.1982 Valid Loss:0.4800 \t Train Acc:93.00 %  Valid Acc:86.33 %\n",
      "Epoch:60/80 \t Train Loss:0.1945 Valid Loss:0.4795 \t Train Acc:93.06 %  Valid Acc:86.53 %\n",
      "Epoch:61/80 \t Train Loss:0.1815 Valid Loss:0.4714 \t Train Acc:93.60 %  Valid Acc:86.76 %\n",
      "Epoch:62/80 \t Train Loss:0.1763 Valid Loss:0.4666 \t Train Acc:93.77 %  Valid Acc:86.88 %\n",
      "Epoch:63/80 \t Train Loss:0.1783 Valid Loss:0.4669 \t Train Acc:93.72 %  Valid Acc:86.84 %\n",
      "Epoch:64/80 \t Train Loss:0.1766 Valid Loss:0.4742 \t Train Acc:93.67 %  Valid Acc:86.81 %\n",
      "Epoch:65/80 \t Train Loss:0.1806 Valid Loss:0.4749 \t Train Acc:93.57 %  Valid Acc:86.71 %\n",
      "Epoch:66/80 \t Train Loss:0.1777 Valid Loss:0.4728 \t Train Acc:93.74 %  Valid Acc:86.79 %\n",
      "Epoch:67/80 \t Train Loss:0.1748 Valid Loss:0.4819 \t Train Acc:93.83 %  Valid Acc:86.81 %\n",
      "Epoch:68/80 \t Train Loss:0.1768 Valid Loss:0.4766 \t Train Acc:93.74 %  Valid Acc:87.04 %\n",
      "Epoch:69/80 \t Train Loss:0.1743 Valid Loss:0.4755 \t Train Acc:93.82 %  Valid Acc:86.90 %\n",
      "Epoch:70/80 \t Train Loss:0.1733 Valid Loss:0.4811 \t Train Acc:93.87 %  Valid Acc:86.87 %\n",
      "Epoch:71/80 \t Train Loss:0.1716 Valid Loss:0.4885 \t Train Acc:93.85 %  Valid Acc:86.71 %\n",
      "Epoch:72/80 \t Train Loss:0.1755 Valid Loss:0.4772 \t Train Acc:93.68 %  Valid Acc:86.96 %\n",
      "Epoch:73/80 \t Train Loss:0.1735 Valid Loss:0.4806 \t Train Acc:93.82 %  Valid Acc:86.84 %\n",
      "Epoch:74/80 \t Train Loss:0.1740 Valid Loss:0.4853 \t Train Acc:93.81 %  Valid Acc:86.85 %\n",
      "Epoch:75/80 \t Train Loss:0.1721 Valid Loss:0.4832 \t Train Acc:93.82 %  Valid Acc:86.91 %\n",
      "Epoch:76/80 \t Train Loss:0.1711 Valid Loss:0.4899 \t Train Acc:93.99 %  Valid Acc:86.74 %\n",
      "Epoch:77/80 \t Train Loss:0.1699 Valid Loss:0.4846 \t Train Acc:93.97 %  Valid Acc:86.49 %\n",
      "Epoch:78/80 \t Train Loss:0.1720 Valid Loss:0.4818 \t Train Acc:93.95 %  Valid Acc:86.83 %\n",
      "Epoch:79/80 \t Train Loss:0.1694 Valid Loss:0.4829 \t Train Acc:94.03 %  Valid Acc:87.03 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 18:32:17,893] Trial 1 finished with value: 86.88 and parameters: {'sigma_1': 0.5340945669600128, 'sigma_2': 2.012561708392316, 'sigma_3': 0.03452267338606485, 'sigma_4': 7.165112415675016, 'sigma_5': 5.710022096981993, 'sigma_6': 7.585482192543815, 'sigma_7': 9.745801957430501, 'sigma_8': 3.625283891054244, 'sigma_9': 6.441710761200471, 'sigma_10': 2.9233715401612925, 'sigma_11': 4.722315315920089, 'sigma_12': 6.307206064673162, 'sigma_13': 1.1530864499956828}. Best is trial 0 with value: 87.37.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:80/80 \t Train Loss:0.1722 Valid Loss:0.4852 \t Train Acc:93.87 %  Valid Acc:86.88 %\n",
      "Best trial:\n",
      "  Value:  87.37\n",
      "  Params: \n",
      "    sigma_1: 4.446965845522028\n",
      "    sigma_2: 2.5738228033584543\n",
      "    sigma_3: 5.484707396012755\n",
      "    sigma_4: 7.447966654690194\n",
      "    sigma_5: 8.198999970169526\n",
      "    sigma_6: 0.24587717173912949\n",
      "    sigma_7: 8.339356211290225\n",
      "    sigma_8: 5.184410352497476\n",
      "    sigma_9: 1.3588377440310206\n",
      "    sigma_10: 3.2682422692579918\n",
      "    sigma_11: 5.9506674592661115\n",
      "    sigma_12: 1.0630871083712756\n",
      "    sigma_13: 6.803571010214274\n"
     ]
    }
   ],
   "source": [
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "learning_rate = 0.001    \n",
    "num_epochs = 80\n",
    "# 定义目标函数\n",
    "def objective(trial):\n",
    "    # 模型实例化\n",
    "    model = ResNet(trial)\n",
    "    model.to(device)\n",
    "    curr_lr = learning_rate\n",
    "    # 损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=curr_lr)  # 保持 Adam 优化器\n",
    "\n",
    "    #history = {'train_loss': [], 'valid_loss': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=curr_lr)  # 保持 Adam 优化器\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            scores, predictions = torch.max(outputs.data, 1)\n",
    "            train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        # Decay learning rate\n",
    "        if (epoch+1) % 20 == 0:\n",
    "            curr_lr /= 3\n",
    "            update_lr(optimizer, curr_lr)\n",
    "\n",
    "        valid_loss, valid_correct = 0.0, 0\n",
    "        model.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * images.size(0)\n",
    "            scores, predictions = torch.max(outputs.data, 1)\n",
    "            valid_correct += (predictions == labels).sum().item()\n",
    "        ##不好的trial剪枝    \n",
    "        if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        valid_loss = valid_loss / len(test_loader.sampler)\n",
    "        valid_acc = valid_correct / len(test_loader.sampler) * 100\n",
    "\n",
    "        print(\"Epoch:{}/{} \\t Train Loss:{:.4f} Valid Loss:{:.4f} \\t Train Acc:{:.2f} %  Valid Acc:{:.2f} %\".format(epoch + 1, num_epochs,\n",
    "                                                                                         train_loss,\n",
    "                                                                                         valid_loss,\n",
    "                                                                                         train_acc,\n",
    "                                                                                         valid_acc))\n",
    "        # history['train_loss'].append(train_loss)\n",
    "        # history['valid_loss'].append(valid_loss)\n",
    "        # history['train_acc'].append(train_acc)\n",
    "        # history['valid_acc'].append(valid_acc)\n",
    "\n",
    "    return valid_acc\n",
    "\n",
    "    \n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# 运行优化过程\n",
    "study.optimize(objective, n_trials=2)\n",
    "\n",
    "# 打印最佳参数和目标值\n",
    "print('Best trial:')\n",
    "print('  Value: ', study.best_trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85f556-7b91-4bf5-b93e-4d9249296abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832c0c8-8a73-4a24-9bc4-6bcd402be601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d533b-c002-4723-808c-92e3f0907b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef6b14-404b-43b6-ac84-08b609779190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
